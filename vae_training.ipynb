{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ofekrosenfeld1/thesis/blob/main/vae_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KczMppEqDCgI"
      },
      "outputs": [],
      "source": [
        "#import relevant libraries\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "import pandas as pd\n",
        "import json\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import ast\n",
        "from multiprocessing import Pool\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from torchsummary import summary\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "repo = 'https://github.com/ofekrosenfeld1/thesis.git'\n",
        "!git clone $repo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayHduOqoyrpd",
        "outputId": "80ac176e-2c6d-4494-b28e-ff232b3b447f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'thesis' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#connect to drive and mount the relevant dataframe from drive"
      ],
      "metadata": {
        "id": "pf2koxu2uqbR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pr2QeSkbjzNs",
        "outputId": "3c33d8a3-bfeb-4534-910f-fc31902e1f55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#connect to google drive in order to mount files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "buP5PdLRi733"
      },
      "outputs": [],
      "source": [
        "#load the chembl pre-processed data into the notebook\n",
        "chembl_df = pd.read_csv('/content/drive/My Drive/chembl_relevant_info_with_numeric_selfies.csv')\n",
        "chembl_df = chembl_df.drop(columns=['Unnamed: 0','Unnamed: 0.1','ChEMBL ID'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "hBI-eTbKqSDH",
        "outputId": "a2f1ecae-73e9-4015-ec36-fa7e2ff32d54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[C][C][=Branch1][C][=O][N][C][C][C][C][Branch2][Ring1][=N][C][=C][C][=C][Branch2][Ring1][C][C][C][O][C][=C][C][Branch1][C][Cl][=C][C][Branch1][C][Cl][=C][Ring1][Branch2][C][=C][Ring1][P][=C][Branch2][Ring1][Ring1][C][=Branch1][C][=O][N][Branch1][C][C][C][C][C][=C][C][=C][C][=C][Ring1][=Branch1][C][Branch1][Branch1][C][Ring2][Ring2][Branch1][N][Ring2][Ring2][Ring2][EOS]\n"
          ]
        }
      ],
      "source": [
        "print(chembl_df['SELFIES'][12345])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "09ooTd2WmD3m"
      },
      "outputs": [],
      "source": [
        "#load the covnersion idxs jsons (selfies - numeric representation and vice versia)\n",
        "with open('/content/drive/My Drive/idx_to_token.json','r') as f:\n",
        "    idx_to_tokens = json.load(f)\n",
        "\n",
        "with open('/content/drive/My Drive/token_to_indx.json','r') as f:\n",
        "    tokens_to_idx = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dD1xMT_cX13U",
        "outputId": "e11b9901-58ae-4457-aeb3-928b0d7a93f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[N-1]\n",
            "211\n"
          ]
        }
      ],
      "source": [
        "print((idx_to_tokens['211']))\n",
        "print((tokens_to_idx['[N-1]']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "WVCFPtWWLji5",
        "outputId": "132d7bc6-a9e4-4cfd-a3ed-3febd727424d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "chembl_df['seq_len'] = chembl_df['numeric_selfies'].str.count(',') + 1\n",
        "plt.figure()\n",
        "plt.hist(chembl_df['seq_len'], bins=50)\n",
        "plt.xlabel('Sequence Length')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Sequence Lengths')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHEIZ8cQUtMA",
        "outputId": "aca44215-e6f9-4c1c-e7f5-f1ea70c772a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "71.0\n"
          ]
        }
      ],
      "source": [
        "percentile_90 = chembl_df['seq_len'].quantile(0.90)\n",
        "print(percentile_90)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7RYjf9xqvZWY"
      },
      "outputs": [],
      "source": [
        "def fast_parse_and_pad(s, max_len, pad_value=0):\n",
        "    \"\"\"\n",
        "    Converts stringified numeric SELFIE to a fixed-length tensor.\n",
        "    Truncates if too long, pads with `pad_value` if too short.\n",
        "    \"\"\"\n",
        "    tokens = list(map(int, s.strip('[]').replace(' ', '').split(',')))\n",
        "    tokens = tokens[:max_len]  # Truncate if longer than max_len\n",
        "\n",
        "    # Pad to max_len\n",
        "    if len(tokens) < max_len:\n",
        "        tokens += [pad_value] * (max_len - len(tokens))\n",
        "\n",
        "    return torch.tensor(tokens, dtype=torch.long)\n",
        "\n",
        "def process_molecules_fixed_length(df, column, max_len, pad_value=0):\n",
        "    \"\"\"\n",
        "    Vectorized fixed-length processing of numeric SELFIE strings.\n",
        "    Returns a list of torch tensors, one per molecule.\n",
        "    \"\"\"\n",
        "    return df[column].apply(lambda s: fast_parse_and_pad(s, max_len, pad_value)).tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "CEpaupugJhyB"
      },
      "outputs": [],
      "source": [
        "tensors = process_molecules_fixed_length(df = chembl_df, column='numeric_selfies', max_len=71, pad_value=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JfNIe2oe9d1",
        "outputId": "0cf97a73-4855-4b66-e168-1241a18081ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([182, 232, 182, 115, 182, 115, 170, 244, 223, 223, 182, 115, 182, 115,\n",
            "        169, 115, 232, 182, 182, 115, 182, 115, 182, 169, 182, 192, 115, 244,\n",
            "          4, 182, 169, 182, 188, 115, 244, 258, 223, 115, 223, 115, 245, 244,\n",
            "          4, 182, 115, 245, 244, 232, 232, 182, 182, 182, 182, 182, 223, 182,\n",
            "        115, 223, 115, 244, 169, 210, 112, 182, 122, 227, 190,   0,   0,   0,\n",
            "          0])\n",
            "1623356\n"
          ]
        }
      ],
      "source": [
        "print(((tensors[10])))\n",
        "print(len(tensors))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YrZovT71qlL3"
      },
      "outputs": [],
      "source": [
        "\n",
        "tensors_for_model = tensors\n",
        "#process the tensors to be a model-ready data\n",
        "#stack the tensors to be in one tensor of shape [N, seq_len]\n",
        "x_tensor = torch.stack(tensors_for_model)\n",
        "#use pytorch approach of creating a dataset object of the big tensor we created before\n",
        "dataset = TensorDataset(x_tensor)\n",
        "#load the data using the needed batch_size, while shuffling the data every epoch\n",
        "dataloader = DataLoader(dataset, batch_size= 64, shuffle=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "mMqJ3MVz1iLr"
      },
      "outputs": [],
      "source": [
        "#the main VAE class, inherits from nn.Module\n",
        "class SelfiesVAE(nn.Module):\n",
        "    #init gets the base properties of the class\n",
        "    #vocab_size = number of tokens in the vocabulary (of the selfies)\n",
        "    #pad_idx = the token used to represent the padding\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, latent_dim, pad_idx,seq_len):\n",
        "        #super().__init__() is needed for inheritance of nn.Module properties\n",
        "        super().__init__()\n",
        "        #the tensor by itself does not contribute any information - or chemical inforamtion, hence an embedding is needed for each SELFIE\n",
        "        #better than one-hot due to lower dim. vector and more information can be passed through embeddings\n",
        "        #padding_idx helps the embedding to know which index was used for padding the tensor - to not count them in the backprop\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
        "        #after the embedding layer, the data is encoded into rnn (gru)\n",
        "        self.encoder_rnn = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n",
        "        #then, the mu and logvar are generated - latent space\n",
        "        self.to_mu = nn.Linear(hidden_dim, latent_dim)\n",
        "        self.to_logvar = nn.Linear(hidden_dim, latent_dim)\n",
        "        #then, the latent space is converted into the hidden linear layer\n",
        "        self.latent_to_hidden = nn.Linear(latent_dim, hidden_dim)\n",
        "        #after going through to the hidden layer, it is potentially possible to add act. func. -can experiment w/ that\n",
        "        #finally, we decode through a gru layer\n",
        "        self.decoder_rnn = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n",
        "        #then - we finally have an output through a linear layer\n",
        "        self.output_layer = nn.Linear(hidden_dim, vocab_size)\n",
        "        #the fixed lenght of a sequence (molecule), defined in the EDA steps\n",
        "        self.seq_len = seq_len\n",
        "        #padding index = 0\n",
        "        self.pad_idx = pad_idx\n",
        "\n",
        "\n",
        "    def encode(self, x):\n",
        "        #x.long() makes the input in the correct format (int) into the embedding, embedding layer accepts integers\n",
        "        x_embed = self.embedding(x.long())\n",
        "        #gets the embedded and encode it through gru\n",
        "        #the output of the gru is outputs, h - but we just want the h, not all the outputs. we are interested in the summery vector of all the timesteps in the gru\n",
        "        _, h = self.encoder_rnn(x_embed)\n",
        "        #take just the needed dimentions\n",
        "        h = h.squeeze(0)\n",
        "        #get the mu out of h\n",
        "        mu = self.to_mu(h)\n",
        "        #get the logvar out of h\n",
        "        logvar = self.to_logvar(h)\n",
        "        return mu, logvar\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        #reparametrization trick - using z = mu + std*eps~N(0,1), this allows to backprop through mu,std - while eps~N(0,1) stays the same\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def decode(self, z, seq_len):\n",
        "        #first, the z latent vector is decoded through linear layer that maps it into the shpe expected by the gru\n",
        "        hidden = self.latent_to_hidden(z).unsqueeze(0)\n",
        "        #get the batch size through z(0) - z is [batch_size, latent_vec_size]\n",
        "        batch_size = z.size(0)\n",
        "        #we need an initial input token to insert the gru - using the pad_idx as initial token\n",
        "        #the shape of the initial input is [batch_size,1]\n",
        "        #torch.long to match the expected type of embedded, then sending it to device\n",
        "        #the \"dummy input token\" is common usage as an initializer of the gru\n",
        "        input_token = torch.full((batch_size, 1), self.pad_idx, dtype=torch.long, device=z.device)\n",
        "        outputs = []\n",
        "\n",
        "        #each time the gru predicts the next token, so we iterate on each token in the seq_len\n",
        "        for _ in range(seq_len):\n",
        "            #get the embdedding of the input token - to get embedding vector of the token\n",
        "            embed = self.embedding(input_token)\n",
        "            #get the prediction (out) of the next token from the gru - based on the previous token\n",
        "            out, hidden = self.decoder_rnn(embed, hidden)\n",
        "            #logits are with shape [batch_size, vocab_size] meaning it maps the probability of each token from the vocabulary based on the output from the gru\n",
        "            #now, instead of each token we have a vector w/ probability of each possible token. remember we have a batch each time so its [batch_size, vocab_size]\n",
        "            logits = self.output_layer(out.squeeze(1))\n",
        "            #save the logits of each timestep\n",
        "            outputs.append(logits)\n",
        "            input_token = logits.argmax(dim=1, keepdim=True)  # Greedy decoding\n",
        "        #the results is stacked list of the output logits for each timestep\n",
        "        return torch.stack(outputs, dim=1)  # [B, L, V]\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "      #forward is important func. - as it inherits from nn.Module to be activates once the model is called\n",
        "      #the output of the forward is the logits (distr. for each token in each timestep) after the decoding, plus the mu,std of the latent space\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        x_hat_logits = self.decode(z, x.size(1))\n",
        "        return x_hat_logits, mu, logvar\n",
        "\n",
        "\n",
        "# === Loss Function ===\n",
        "\n",
        "def vae_loss(x_hat_logits, x_true, mu, logvar, pad_idx):\n",
        "  #we use the cross_entropy as the reconstruction loss - makes the most sense\n",
        "  #here we do it token by token\n",
        "  #the -1 flattens it\n",
        "  #ignoring the pad index for loss calc ofc\n",
        "  #\n",
        "    recon_loss = F.cross_entropy(\n",
        "        x_hat_logits.view(-1, x_hat_logits.size(-1)),\n",
        "        x_true.view(-1),\n",
        "        ignore_index=pad_idx,\n",
        "        reduction='mean'\n",
        "    )\n",
        "    #also, we use the kl divergence as a regularization that the latent dist. behave like a gaussian dist. - keepin it as smooth as possible\n",
        "    kl_div = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return recon_loss + kl_div, recon_loss, kl_div\n",
        "\n",
        "\n",
        "# === Training Setup ===\n",
        "\n",
        "def train_vae(model, dataloader, optimizer, device, pad_idx, num_epochs):\n",
        "    #sets the params into training setup\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        total_recon = 0\n",
        "        total_kl = 0\n",
        "        #loop is an approach to define dataloader just with tdqm method(for process bars)\n",
        "        loop = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "        #looping through each batch\n",
        "        for (x_batch,) in loop:\n",
        "            x_batch = x_batch.to(device)\n",
        "            #first resetting the gradients in the optimizer - independent each batch\n",
        "            optimizer.zero_grad()\n",
        "            #calc the x_hat, mu,var with model(batch) -> applying forward method\n",
        "            x_hat_logits, mu, logvar = model(x_batch)\n",
        "            #calc loss of the output\n",
        "            loss, recon, kl = vae_loss(x_hat_logits, x_batch, mu, logvar, pad_idx)\n",
        "            #do backprop based on the loss\n",
        "            loss.backward()\n",
        "            #update the model weights properly to the backprop\n",
        "            optimizer.step()\n",
        "            #collecting info for each loop to estimate how the model did over epochs\n",
        "            #loss is a tensor, hence by .item() you get the number only\n",
        "            total_loss += loss.item()\n",
        "            total_recon += recon.item()\n",
        "            total_kl += kl.item()\n",
        "            loop.set_postfix(loss=loss.item(), recon=recon.item(), kl=kl.item())\n",
        "\n",
        "        print(f\"Epoch {epoch+1} - Loss: {total_loss:.2f}, Recon: {total_recon:.2f}, KL: {total_kl:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wL5Btrpxbcco"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lwW8eOBgW9X8",
        "outputId": "9de17902-a10f-41f3-b8a7-8ee2a46dd7d4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/20: 100%|██████████| 25365/25365 [32:06<00:00, 13.17it/s, kl=0.2, loss=1.99, recon=1.79]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 - Loss: 54271.84, Recon: 50690.51, KL: 3581.33\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/20: 100%|██████████| 25365/25365 [32:08<00:00, 13.15it/s, kl=0.248, loss=1.99, recon=1.74]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 - Loss: 51236.66, Recon: 45473.52, KL: 5763.14\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/20: 100%|██████████| 25365/25365 [32:12<00:00, 13.13it/s, kl=0.279, loss=1.91, recon=1.63]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 - Loss: 49870.86, Recon: 43219.10, KL: 6651.77\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/20: 100%|██████████| 25365/25365 [31:53<00:00, 13.26it/s, kl=0.298, loss=1.93, recon=1.63]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 - Loss: 48800.11, Recon: 41490.70, KL: 7309.41\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/20: 100%|██████████| 25365/25365 [31:44<00:00, 13.32it/s, kl=0.315, loss=1.84, recon=1.53]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5 - Loss: 47618.05, Recon: 39647.80, KL: 7970.24\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/20: 100%|██████████| 25365/25365 [31:35<00:00, 13.38it/s, kl=0.331, loss=1.88, recon=1.55]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6 - Loss: 47263.57, Recon: 38700.50, KL: 8563.07\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/20:  57%|█████▋    | 14515/25365 [18:18<13:38, 13.25it/s, kl=0.351, loss=1.88, recon=1.53]"
          ]
        }
      ],
      "source": [
        "\n",
        "if __name__ == \"__main__\":\n",
        "    #vocab size is the size of your unique tokens in your index, including padding idx\n",
        "    vocab_size = len(idx_to_tokens)\n",
        "    #seqeunce lenght - fixed lenght for all tensors describing the molecules, predefined before\n",
        "    seq_len = 71\n",
        "    #embedding size vector initialy set to 256\n",
        "    embedding_dim = 256\n",
        "    #hidden layer also 256\n",
        "    hidden_dim = 256\n",
        "    #latent dim would be 64\n",
        "    latent_dim = 64\n",
        "    #padding idx is 0\n",
        "    pad_idx = 0\n",
        "    #10 epochs, 32 molecules each time\n",
        "    num_epochs = 20\n",
        "    batch_size = 64\n",
        "    learning_rate = 1e-3\n",
        "    #set up the model with the dimenstions mentioned before\n",
        "    model = SelfiesVAE(vocab_size, embedding_dim, hidden_dim, latent_dim, pad_idx,seq_len)\n",
        "    #set up the device\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    #send model to device\n",
        "    model = SelfiesVAE(vocab_size, embedding_dim, hidden_dim, latent_dim, pad_idx,seq_len).to(device)\n",
        "    #set up the ADAM optimizer\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    # Train the model\n",
        "    train_vae(model, dataloader, optimizer, device, pad_idx, num_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "collapsed": true,
        "id": "nHeOXp9l8N75"
      },
      "outputs": [],
      "source": [
        "#saving the model paramaters in drive to re-use them later on for further experiment\n",
        "# save only the model parameters (recommended)\n",
        "torch.save(model.state_dict(), 'vae_selfies_all_data_exp.pt')\n",
        "#download to the local machine (optional)\n",
        "from google.colab import files\n",
        "files.download('vae_selfies_all_data_exp.pt')\n",
        "#save to google drive\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/vae_selfies_all_data_exp.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbLQrqtzK-fK",
        "outputId": "4335102b-a06e-4375-9be7-b9e47c77a5b7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#loading saved weights from saved weights of experimental model\n",
        "vocab_size = len(idx_to_tokens)\n",
        "seq_len = 71\n",
        "embedding_dim = 256\n",
        "hidden_dim = 256\n",
        "latent_dim = 64\n",
        "pad_idx = 0\n",
        "num_epochs = 20\n",
        "batch_size = 64\n",
        "learning_rate = 1e-3\n",
        "model = SelfiesVAE(vocab_size, embedding_dim, hidden_dim, latent_dim, pad_idx,seq_len)\n",
        "#set up the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "#send model to device\n",
        "model = SelfiesVAE(vocab_size, embedding_dim, hidden_dim, latent_dim, pad_idx,seq_len).to(device)\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/vae_selfies_500k_first_exp.pt'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDOeDmNj2tR8",
        "outputId": "01368409-a866-470c-e7ad-7da89f5d63d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([182, 182, 169, 182, 182, 169, 182, 182, 182, 115, 258, 182, 170, 245,\n",
            "        245, 223, 182, 112, 182, 122, 182, 182, 115, 223, 169,   5, 182, 182,\n",
            "        115, 182, 115, 182, 115, 244, 112, 182, 115, 182, 115, 169, 244, 182,\n",
            "          9, 182, 115, 245, 244, 182, 244, 170, 120, 245, 244, 232, 190,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0])\n",
            "['[C]', '[C]', '[Branch1]', '[C]', '[C]', '[Branch1]', '[C]', '[C]', '[C]', '[=C]', '[C]', '[=C]', '[Branch2]', '[Ring1]', '[P]', '[N]', '[C]', '[=Branch1]', '[C]', '[=O]', '[C]', '[C]', '[C]', '[C]', '[C]', '[C]', '[C]', '[C]', '[C]', '[C]', '[C]', '[C]', '[C]', '[C]', '[C]', '[C]', '[C]', '[C]', '[C]', '[C]', '[C]', '[C]', '[C]', '[C]', '[C]', '[Ring1]', '[Ring1]', '[C]', '[C]', '[C]', '[Ring2]', '[Ring1]', '[Ring1]', '[EOS]', '[EOS]', '[EOS]', '[EOS]', '[EOS]', '[EOS]', '[EOS]', '[EOS]', '[EOS]', '[EOS]', '[EOS]', '[EOS]', '[EOS]', '[EOS]', '[EOS]', '[EOS]', '[EOS]', '[EOS]'] 71\n",
            "['[C]', '[C]', '[Branch1]', '[C]', '[C]', '[Branch1]', '[C]', '[C]', '[C]', '[=C]', '[S]', '[C]', '[Branch2]', '[Ring2]', '[Ring2]', '[N]', '[C]', '[=Branch1]', '[C]', '[=O]', '[C]', '[C]', '[=C]', '[N]', '[Branch1]', '[#Branch2]', '[C]', '[C]', '[=C]', '[C]', '[=C]', '[C]', '[=C]', '[Ring1]', '[=Branch1]', '[C]', '[=C]', '[C]', '[=C]', '[Branch1]', '[Ring1]', '[C]', '[#N]', '[C]', '[=C]', '[Ring2]', '[Ring1]', '[C]', '[Ring1]', '[Branch2]', '[=N]', '[Ring2]', '[Ring1]', '[O]', '[EOS]', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>'] 71\n"
          ]
        }
      ],
      "source": [
        "from __future__ import generator_stop\n",
        "#NOW - generate a new molecule from the VAE based on an input molecule\n",
        "mol = tensors[1000000]\n",
        "print(mol)\n",
        "x = mol.unsqueeze(0).to(device)\n",
        "#use eval mode - to not accidently activate all the behaviors of .train() mode\n",
        "# make sure model is in eval mode - no_grad saves memory and time, ensure inference mode\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    #encode the mu, logvar that represents your molecule\n",
        "    mu, logvar = model.encode(x)\n",
        "    z = model.reparameterize(mu, logvar)  # shape: [1, latent_dim]\n",
        "    #decode your sampled molecule from the latent space\n",
        "    logits = model.decode(z, seq_len)\n",
        "    token_ids = logits.argmax(dim=2)[0]  # [seq_len]\n",
        "    generated_tokens = [idx_to_tokens[str(i.item())] for i in token_ids]\n",
        "    original_mol = [idx_to_tokens[str(i.item())] for i in x[0]]\n",
        "    print(generated_tokens, len(generated_tokens))\n",
        "    print(original_mol, len(original_mol))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyO4ZLmKrGM922jedZmn2n22",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}